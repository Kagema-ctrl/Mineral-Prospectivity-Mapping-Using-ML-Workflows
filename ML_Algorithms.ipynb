{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy, os, pandas as pd, numpy as np\n",
    "from arcpy.sa import *\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "gdb = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\"   # GDB that contains your TrainingPoints\n",
    "points_fc = \"TrainingPts\"                                              # enriched points with raster values\n",
    "label_field = \"Label\"                                                     # 1 = occurrence, 0 = background\n",
    "cell_size_m = 5000                                                        # fishnet cell size (meters) ‚Üí try 5,000 first\n",
    "fishnet_fc  = \"CV_Fishnet_5km\"                                            # fishnet output name (in the same GDB)\n",
    "points_with_blocks = \"TrainingPoints_blocks\"                               # points + block_id (output)\n",
    "\n",
    "arcpy.env.workspace = gdb\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Points CRS: Arc_1960_UTM_Zone_36N | Linear unit: Meter\n",
      "‚úÖ Fishnet created: C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\\CV_Fishnet_5km\n",
      "‚úÖ block_id populated from OID\n",
      "üéØ Done. Points with blocks ‚Üí C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\\TrainingPoints_blocks\n",
      "   Fishnet cells: 324\n"
     ]
    }
   ],
   "source": [
    "# === Build fishnet over training points (NO CLIP), add block_id, join to points ===\n",
    "# Expects: points_fc, gdb, fishnet_fc, cell_size_m to be defined earlier.\n",
    "\n",
    "import arcpy, os\n",
    "arcpy.env.workspace = gdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# 0) CRS sanity (fishnet size is in meters)\n",
    "sr = arcpy.Describe(points_fc).spatialReference\n",
    "print(f\"[Info] Points CRS: {sr.name} | Linear unit: {getattr(sr, 'linearUnitName', 'N/A')}\")\n",
    "if getattr(sr, \"linearUnitName\", \"\").lower() != \"meter\":\n",
    "    print(\"‚ö†Ô∏è  Consider projecting to a meter-based CRS; fishnet size is in meters.\")\n",
    "\n",
    "# Defaults if not set\n",
    "fishnet_fc = globals().get(\"fishnet_fc\", \"CV_Fishnet_5km\")\n",
    "cell_size_m = float(globals().get(\"cell_size_m\", 5000))\n",
    "\n",
    "# 1) Build fishnet over the points' extent\n",
    "ext = arcpy.Describe(points_fc).extent\n",
    "origin     = f\"{ext.XMin} {ext.YMin}\"\n",
    "y_axis     = f\"{ext.XMin} {ext.YMin + 10}\"    # small offset defines Y-axis direction\n",
    "opp_corner = f\"{ext.XMax} {ext.YMax}\"\n",
    "\n",
    "fishnet_path = os.path.join(gdb, fishnet_fc)\n",
    "if arcpy.Exists(fishnet_path):\n",
    "    arcpy.management.Delete(fishnet_path)\n",
    "\n",
    "arcpy.management.CreateFishnet(\n",
    "    out_feature_class=fishnet_path,\n",
    "    origin_coord=origin,\n",
    "    y_axis_coord=y_axis,\n",
    "    cell_width=cell_size_m,\n",
    "    cell_height=cell_size_m,\n",
    "    number_rows=0, number_columns=0,\n",
    "    corner_coord=opp_corner,\n",
    "    labels=\"NO_LABELS\",\n",
    "    template=\"#\",\n",
    "    geometry_type=\"POLYGON\"\n",
    ")\n",
    "print(\"‚úÖ Fishnet created:\", fishnet_path)\n",
    "\n",
    "# 2) Add a stable block_id from the fishnet's OID\n",
    "oid_field = arcpy.Describe(fishnet_path).OIDFieldName\n",
    "if \"block_id\" not in [f.name for f in arcpy.ListFields(fishnet_path)]:\n",
    "    arcpy.management.AddField(fishnet_path, \"block_id\", \"LONG\")\n",
    "arcpy.management.CalculateField(fishnet_path, \"block_id\", f\"!{oid_field}!\", \"PYTHON3\")\n",
    "print(\"‚úÖ block_id populated from\", oid_field)\n",
    "\n",
    "# 3) Spatial join: attach block_id to your training points\n",
    "points_with_blocks = os.path.join(gdb, \"TrainingPoints_blocks\")\n",
    "if arcpy.Exists(points_with_blocks):\n",
    "    arcpy.management.Delete(points_with_blocks)\n",
    "\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=points_fc,\n",
    "    join_features=fishnet_path,\n",
    "    out_feature_class=points_with_blocks,\n",
    "    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"INTERSECT\"\n",
    ")\n",
    "\n",
    "# Ensure the field is exactly named 'block_id' (SJ can rename/qualify)\n",
    "joined_fields = [f.name for f in arcpy.ListFields(points_with_blocks)]\n",
    "if \"block_id\" not in joined_fields:\n",
    "    cand = [n for n in joined_fields if n.lower().endswith(\".block_id\") or \"block_id\" in n.lower()]\n",
    "    if cand:\n",
    "        src = cand[0]\n",
    "        arcpy.management.AddField(points_with_blocks, \"block_id\", \"LONG\")\n",
    "        arcpy.management.CalculateField(points_with_blocks, \"block_id\", f\"!{src}!\", \"PYTHON3\")\n",
    "\n",
    "print(\"üéØ Done. Points with blocks ‚Üí\", points_with_blocks)\n",
    "print(\"   Fishnet cells:\", arcpy.management.GetCount(fishnet_path)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Friday, September 26, 2025 11:07:28 AM<br>Succeeded at Friday, September 26, 2025 11:07:29 AM (Elapsed Time: 0.29 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\CV_Fishnet_5km'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stable block_id from OBJECTID\n",
    "if \"block_id\" not in [f.name for f in arcpy.ListFields(fishnet_path)]:\n",
    "    arcpy.management.AddField(fishnet_path, \"block_id\", \"LONG\")\n",
    "arcpy.management.CalculateField(fishnet_path, \"block_id\", \"!OID!\", \"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2 class='msg-title'>Messages</h2><div id='messages'>Start Time: Friday, September 26, 2025 11:07:30 AM<br>Succeeded at Friday, September 26, 2025 11:07:32 AM (Elapsed Time: 1.63 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\TrainingPoints_blocks'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spatial join: write block_id to each point\n",
    "pts_blocks_path = os.path.join(gdb, points_with_blocks)\n",
    "if arcpy.Exists(pts_blocks_path):\n",
    "    arcpy.management.Delete(pts_blocks_path)\n",
    "\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=points_fc,\n",
    "    join_features=fishnet_path,\n",
    "    out_feature_class=pts_blocks_path,\n",
    "    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"INTERSECT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fishnet created: C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\\CV_Fishnet_5km\n",
      "‚úÖ Points with blocks: C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\\TrainingPoints_blocks\n"
     ]
    }
   ],
   "source": [
    "# ensure field is named block_id (field mapping sometimes renames)\n",
    "joined_fields = [f.name for f in arcpy.ListFields(pts_blocks_path)]\n",
    "if \"block_id\" not in joined_fields:\n",
    "    cand = [n for n in joined_fields if n.lower().endswith(\".block_id\") or \"block_id\" in n.lower()]\n",
    "    if cand:\n",
    "        src = cand[0]\n",
    "        arcpy.management.AddField(pts_blocks_path, \"block_id\", \"LONG\")\n",
    "        arcpy.management.CalculateField(pts_blocks_path, \"block_id\", f\"!{src}!\", \"PYTHON3\")\n",
    "\n",
    "print(f\"‚úÖ Fishnet created: {fishnet_path}\")\n",
    "print(f\"‚úÖ Points with blocks: {pts_blocks_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Rows: 409 | Pos: 68 | Neg: 341 | Blocks: 133\n"
     ]
    }
   ],
   "source": [
    "# --- READ TO PANDAS & PICK PREDICTORS (cleaned: exclude IDs/admin; safety drop) ---\n",
    "import arcpy, pandas as pd, numpy as np, re\n",
    "\n",
    "# 1) Numeric predictors only, skip obvious admin fields\n",
    "num_types = {\"Double\",\"Single\",\"Integer\",\"SmallInteger\"}\n",
    "all_fields = arcpy.ListFields(pts_blocks_path)\n",
    "\n",
    "skip_names = {\n",
    "    label_field.lower(),\n",
    "    \"block_id\",\"objectid\",\"oid\",\"fid\",\n",
    "    \"target_fid\",\"orig_fid\",\"join_count\",\n",
    "    \"shape\",\"shape_length\",\"shape_area\"\n",
    "}\n",
    "\n",
    "feature_fields = [\n",
    "    f.name for f in all_fields\n",
    "    if (f.type in num_types and f.name.lower() not in skip_names)\n",
    "]\n",
    "\n",
    "# 2) Pull rows\n",
    "rows = []\n",
    "with arcpy.da.SearchCursor(pts_blocks_path, feature_fields + [label_field,\"block_id\",\"SHAPE@XY\"]) as cur:\n",
    "    for *vals, lab, blk, xy in cur:\n",
    "        rows.append({**dict(zip(feature_fields, vals)),\n",
    "                     \"label\": int(lab), \"block_id\": int(blk),\n",
    "                     \"x\": xy[0], \"y\": xy[1]})\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"[Info] Rows: {len(df)} | Pos: {(df['label']==1).sum()} | Neg: {(df['label']==0).sum()} | Blocks: {df['block_id'].nunique()}\")\n",
    "\n",
    "# 3) SAFER: drop only integer, ~unique, and ID-like names\n",
    "id_name_pat = re.compile(r\"(?:^|_)(?:id|fid|oid|target|orig|join|index)(?:_|$)\", re.I)\n",
    "idish = [\n",
    "    c for c in feature_fields\n",
    "    if c in df.columns\n",
    "    and pd.api.types.is_integer_dtype(df[c])\n",
    "    and (df[c].nunique() / len(df) > 0.98)\n",
    "    and id_name_pat.search(c) is not None\n",
    "]\n",
    "if idish:\n",
    "    print(\"Dropping likely integer ID fields:\", idish)\n",
    "    feature_fields = [c for c in feature_fields if c not in idish]\n",
    "    df = df[feature_fields + [\"label\",\"block_id\",\"x\",\"y\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_cols = [c for c in feature_fields if c.lower().startswith(\"lith_\")]\n",
    "cont_cols = [c for c in feature_fields if c not in lith_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cont_cols + lith_cols]\n",
    "y = df[\"label\"].values.astype(int)\n",
    "groups = df[\"block_id\"].values\n",
    "\n",
    "# preprocessors: impute both; scale only continuous for SVM\n",
    "rf_prep = ColumnTransformer([\n",
    "    (\"cont_impute\", SimpleImputer(strategy=\"median\"), cont_cols),\n",
    "    (\"lith_impute\", SimpleImputer(strategy=\"most_frequent\"), lith_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "svm_prep = ColumnTransformer([\n",
    "    (\"cont_pipe\", Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\",  StandardScaler(with_mean=True, with_std=True))\n",
    "    ]), cont_cols),\n",
    "    (\"lith_impute\", SimpleImputer(strategy=\"most_frequent\"), lith_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "def eval_groupcv(model_builder, X, y, groups, n_splits=5):\n",
    "    \"\"\"Short: run GroupKFold CV by block, print ROC-AUC & PR-AUC per fold.\"\"\"\n",
    "    uniq = np.unique(groups).size\n",
    "    n_splits = min(n_splits, max(3, min(5, uniq)))   # keep between 3‚Äì5 and ‚â§ unique blocks\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    roc_list, pr_list = [], []\n",
    "\n",
    "    for i, (tr, te) in enumerate(gkf.split(X, y, groups), 1):\n",
    "        model = model_builder()\n",
    "        model.fit(X.iloc[tr], y[tr])\n",
    "        proba = model.predict_proba(X.iloc[te])[:,1]\n",
    "        pred  = (proba >= 0.5).astype(int)\n",
    "        roc = roc_auc_score(y[te], proba)\n",
    "        pr  = average_precision_score(y[te], proba)\n",
    "        roc_list.append(roc); pr_list.append(pr)\n",
    "        print(f\"Fold {i}: ROC-AUC={roc:.3f} | PR-AUC={pr:.3f}\")\n",
    "    print(f\"‚ûï Mean ROC-AUC={np.mean(roc_list):.3f} (¬±{np.std(roc_list):.3f})\")\n",
    "    print(f\"‚ûï Mean PR-AUC ={np.mean(pr_list):.3f} (¬±{np.std(pr_list):.3f})\")\n",
    "    return np.mean(roc_list), np.mean(pr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rf():\n",
    "    \"\"\"Short: RF pipeline with imputation; class_weight balances 0/1 without SMOTE.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"prep\", rf_prep),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=500, max_depth=None, min_samples_leaf=3,\n",
    "            class_weight=\"balanced\", n_jobs=-1, random_state=42\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm():\n",
    "    \"\"\"Short: SVM(RBF) pipeline; scale continuous only; class_weight balances 0/1.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"prep\", svm_prep),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", C=5.0, gamma=\"scale\",\n",
    "                    class_weight=\"balanced\", probability=True, random_state=42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest : Spatial GroupKFold ===\n",
      "Fold 1: ROC-AUC=0.932 | PR-AUC=0.867\n",
      "Fold 2: ROC-AUC=0.938 | PR-AUC=0.735\n",
      "Fold 3: ROC-AUC=0.998 | PR-AUC=0.990\n",
      "Fold 4: ROC-AUC=0.961 | PR-AUC=0.560\n",
      "Fold 5: ROC-AUC=0.988 | PR-AUC=0.500\n",
      "‚ûï Mean ROC-AUC=0.963 (¬±0.026)\n",
      "‚ûï Mean PR-AUC =0.731 (¬±0.183)\n",
      "\n",
      "=== SVM (RBF) : Spatial GroupKFold ===\n",
      "Fold 1: ROC-AUC=0.907 | PR-AUC=0.747\n",
      "Fold 2: ROC-AUC=0.923 | PR-AUC=0.736\n",
      "Fold 3: ROC-AUC=0.993 | PR-AUC=0.961\n",
      "Fold 4: ROC-AUC=0.894 | PR-AUC=0.390\n",
      "Fold 5: ROC-AUC=0.950 | PR-AUC=0.200\n",
      "‚ûï Mean ROC-AUC=0.933 (¬±0.035)\n",
      "‚ûï Mean PR-AUC =0.607 (¬±0.274)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Random Forest : Spatial GroupKFold ===\")\n",
    "rf_roc, rf_pr = eval_groupcv(build_rf, X, y, groups, n_splits=5)\n",
    "\n",
    "print(\"\\n=== SVM (RBF) : Spatial GroupKFold ===\")\n",
    "svm_roc, svm_pr = eval_groupcv(build_svm, X, y, groups, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest : Spatial hold-out (25% blocks) ===\n",
      "ROC-AUC: 0.965 | PR-AUC: 0.864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.887     0.947     0.916        75\n",
      "           1      0.765     0.591     0.667        22\n",
      "\n",
      "    accuracy                          0.866        97\n",
      "   macro avg      0.826     0.769     0.791        97\n",
      "weighted avg      0.860     0.866     0.860        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "tr, te = next(gss.split(X, y, groups))\n",
    "\n",
    "rf = build_rf()\n",
    "rf.fit(X.iloc[tr], y[tr])\n",
    "proba = rf.predict_proba(X.iloc[te])[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Random Forest : Spatial hold-out (25% blocks) ===\")\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y[te], proba), 3),\n",
    "      \"| PR-AUC:\", round(average_precision_score(y[te], proba), 3))\n",
    "print(classification_report(y[te], pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 RF features:\n",
      " As          0.107583\n",
      "FebyMn      0.082736\n",
      "Mn          0.072107\n",
      "Zn          0.062316\n",
      "W           0.050665\n",
      "Cu          0.042352\n",
      "Sb          0.042158\n",
      "V           0.041038\n",
      "Cr          0.033784\n",
      "Rb          0.032864\n",
      "Bi          0.030889\n",
      "Pb          0.025957\n",
      "Th          0.024638\n",
      "ClayAIOH    0.023655\n",
      "Tl          0.021669\n",
      "ferrous     0.020711\n",
      "OM          0.020321\n",
      "UbyK        0.019916\n",
      "Na          0.019488\n",
      "dem10       0.017103\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_feature_names = cont_cols + lith_cols\n",
    "rf_clf = rf.named_steps[\"clf\"]\n",
    "imp = (pd.Series(rf_clf.feature_importances_, index=final_feature_names)\n",
    "         .sort_values(ascending=False)\n",
    "         .head(20))\n",
    "print(\"\\nTop 20 RF features:\\n\", imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF tuned ‚Äî ROC-AUC: 0.966 PR-AUC: 0.759\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "def build_rf_tuned():\n",
    "    return Pipeline([\n",
    "        (\"prep\", rf_prep),  # your existing preprocessor\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=800,        # a bit more trees\n",
    "            min_samples_leaf=5,      # more regularization\n",
    "            max_depth=None,          # or try 20 if you prefer\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1, random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "roc, pr = [], []\n",
    "for tr, te in gkf.split(X, y, groups):\n",
    "    m = build_rf_tuned().fit(X.iloc[tr], y[tr])\n",
    "    p = m.predict_proba(X.iloc[te])[:,1]\n",
    "    roc.append(roc_auc_score(y[te], p))\n",
    "    pr.append(average_precision_score(y[te], p))\n",
    "print(\"RF tuned ‚Äî ROC-AUC:\", np.mean(roc).round(3), \"PR-AUC:\", np.mean(pr).round(3))\n",
    "rf = build_rf_tuned().fit(X, y)   # fit on ALL data for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-chosen threshold (F2-opt): 0.434  |  P=0.756  R=0.912\n",
      "OOF ROC-AUC: 0.968 | OOF PR-AUC: 0.821\n",
      "\n",
      "=== Random Forest (clean spatial hold-out) ===\n",
      "ROC-AUC: 0.98 | PR-AUC: 0.9\n",
      "Confusion matrix @th 0.4338329465378296 :\n",
      " [[76  5]\n",
      " [ 0 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.938     0.968        81\n",
      "           1      0.821     1.000     0.902        23\n",
      "\n",
      "    accuracy                          0.952       104\n",
      "   macro avg      0.911     0.969     0.935       104\n",
      "weighted avg      0.961     0.952     0.954       104\n",
      "\n",
      "\n",
      "Model ready for mapping: variable `rf` + threshold THRESH_RF = 0.4338329465378296\n"
     ]
    }
   ],
   "source": [
    "# === Choose threshold the right way (OOF) and check a clean spatial hold-out ===\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1) OOF predictions under GroupKFold (no leakage)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "oof_proba = np.zeros(len(y), dtype=float)\n",
    "\n",
    "for tr, te in gkf.split(X, y, groups):\n",
    "    m = build_rf_tuned().fit(X.iloc[tr], y[tr])\n",
    "    oof_proba[te] = m.predict_proba(X.iloc[te])[:, 1]\n",
    "\n",
    "# Pick threshold on OOF PR curve (recall-weighted F2)\n",
    "prec, rec, thr = precision_recall_curve(y, oof_proba)\n",
    "beta = 2\n",
    "f2 = (1+beta**2) * (prec*rec) / ((beta**2)*prec + rec + 1e-9)\n",
    "k = f2.argmax()\n",
    "THRESH_RF = float(thr[max(k-1, 0)])\n",
    "\n",
    "print(f\"OOF-chosen threshold (F2-opt): {THRESH_RF:.3f}  |  P={prec[k]:.3f}  R={rec[k]:.3f}\")\n",
    "print(\"OOF ROC-AUC:\", round(roc_auc_score(y, oof_proba), 3),\n",
    "      \"| OOF PR-AUC:\", round(average_precision_score(y, oof_proba), 3))\n",
    "\n",
    "# 2) Clean spatial hold-out using that threshold\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=123)\n",
    "tr, te = next(gss.split(X, y, groups))\n",
    "\n",
    "rf_hold = build_rf_tuned().fit(X.iloc[tr], y[tr])\n",
    "proba_te = rf_hold.predict_proba(X.iloc[te])[:, 1]\n",
    "pred_te  = (proba_te >= THRESH_RF).astype(int)\n",
    "\n",
    "print(\"\\n=== Random Forest (clean spatial hold-out) ===\")\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y[te], proba_te), 3),\n",
    "      \"| PR-AUC:\", round(average_precision_score(y[te], proba_te), 3))\n",
    "print(\"Confusion matrix @th\", THRESH_RF, \":\\n\", confusion_matrix(y[te], pred_te))\n",
    "print(classification_report(y[te], pred_te, digits=3))\n",
    "\n",
    "# 3) Final model for deployment (fit on ALL data) + keep threshold\n",
    "rf = build_rf_tuned().fit(X, y)\n",
    "print(\"\\nModel ready for mapping: variable `rf` + threshold THRESH_RF =\", THRESH_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidate rasters: 63\n",
      "Candidate rasters:  ['C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\ClayAIOH.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\dem10.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\distfaults2.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\ferrous.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\ironoxide.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\Curv_Plan_10', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\Curv_Profile_10', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\Curvature_Gen10', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\MPM_LIRHANDA_CORRIDOR\\\\MPM_LIRHANDA_CORRIDOR.gdb\\\\Slope_10', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_And_11.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_BIF_15.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Bpl_17.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Bsl_13.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Bs_43.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Cgl_5.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Dac_12.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Dd_28.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Gc_21.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Gl_20.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Gnt_40.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Gn_18.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Grt_4.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Kv_41.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Mud_3.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Ny_42.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Phy_39.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Rhy_10.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Sy_23.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Tuf_14.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\RASTERS FOR ML\\\\LITHOLOGY LAYERS\\\\Lith_Tv_31.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Ag.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\As.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Bi.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Cu.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Pb.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Sb.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Tl.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\W.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\PATHFINDERS\\\\Zn.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\FebyMn.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\KbyAl.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\KbyNa.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\KbyRb.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\KbyTi.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\ThbyK.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\key ratio rasters\\\\UbyK.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\COVARIATES\\\\OM.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\COVARIATES\\\\PH.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Al.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Ca.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Cr.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Fe.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\K.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Mg.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Mn.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Na.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Ni.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Rb.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Th.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Ti.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\U.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\V.tif', 'C:\\\\Users\\\\USER\\\\Desktop\\\\PROJECTS\\\\ESRI\\\\DATA\\\\GEOCHEMICAL LAYERS\\\\Alteration  lithology context\\\\Zr.tif']\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "# ---- Paths (edit if needed) -------------------------------------------------\n",
    "REF_RASTER = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\RASTERS FOR ML\\dem10.tif\"  # alignment reference\n",
    "OUT_DIR    = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\OUTPUTS\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_PROB = os.path.join(OUT_DIR, \"Prospectivity_RF.tif\")\n",
    "OUT_BIN  = os.path.join(OUT_DIR, \"Targets_RF_binary.tif\")\n",
    "\n",
    "# Folders\n",
    "ml_folder   = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\RASTERS FOR ML\"\n",
    "lith_folder = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\RASTERS FOR ML\\LITHOLOGY LAYERS\"\n",
    "geochem_folder = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\GEOCHEMICAL LAYERS\\PATHFINDERS\"\n",
    "ratios_folder = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\GEOCHEMICAL LAYERS\\key ratio rasters\"\n",
    "covars_folder = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\GEOCHEMICAL LAYERS\\COVARIATES\"\n",
    "alter_geochem_folder = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\GEOCHEMICAL LAYERS\\Alteration  lithology context\"\n",
    "gdb         = r\"C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\MPM_LIRHANDA_CORRIDOR\\MPM_LIRHANDA_CORRIDOR.gdb\"\n",
    "\n",
    "# Candidate rasters (continuous + GDB + all lithology one-hots)\n",
    "candidates = [\n",
    "    os.path.join(ml_folder, \"ClayAIOH.tif\"),\n",
    "    os.path.join(ml_folder, \"dem10.tif\"),\n",
    "    os.path.join(ml_folder, \"distfaults2.tif\"),\n",
    "    os.path.join(ml_folder, \"ferrous.tif\"),\n",
    "    os.path.join(ml_folder, \"ironoxide.tif\"),\n",
    "    os.path.join(gdb, \"Curv_Plan_10\"),\n",
    "    os.path.join(gdb, \"Curv_Profile_10\"),\n",
    "    os.path.join(gdb, \"Curvature_Gen10\"),\n",
    "    os.path.join(gdb, \"Slope_10\"),\n",
    "] + glob.glob(os.path.join(lith_folder, \"*.tif\"))  # Lithology rasters\n",
    "\n",
    "# Adding geochemical rasters from the specified folders\n",
    "geochemical_folders = [geochem_folder, ratios_folder, covars_folder, alter_geochem_folder]\n",
    "for folder in geochemical_folders:\n",
    "    candidates += glob.glob(os.path.join(folder, \"*.tif\"))\n",
    "\n",
    "# Manual name overrides (helps when field names differ from file names)\n",
    "manual = {\n",
    "    \"dem10\":                os.path.join(ml_folder, \"dem10.tif\"),\n",
    "    \"distfaults2\":          os.path.join(ml_folder, \"distfaults2.tif\"),\n",
    "    \"clayaloh\":             os.path.join(ml_folder, \"ClayAIOH.tif\"),\n",
    "    \"ironoxide\":            os.path.join(ml_folder, \"ironoxide.tif\"),\n",
    "    \"ferrous\":              os.path.join(ml_folder, \"ferrous.tif\"),\n",
    "    \"curvature_gen10\":      os.path.join(gdb, \"Curvature_Gen10\"),\n",
    "    \"slope_10\":             os.path.join(gdb, \"Slope_10\"),\n",
    "    \"curv_plan_10\":         os.path.join(gdb, \"Curv_Plan_10\"),\n",
    "    \"curv_profile_10\":      os.path.join(gdb, \"Curv_Profile_10\"),\n",
    "}\n",
    "\n",
    "# Output final list of candidate rasters\n",
    "print(f\"Total candidate rasters: {len(candidates)}\")\n",
    "print(\"Candidate rasters: \", candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature ‚Üí raster paths resolved: 59 features\n"
     ]
    }
   ],
   "source": [
    "def base(p):  # dataset name without extension\n",
    "    return os.path.splitext(os.path.basename(p))[0]\n",
    "def norm(s):  # simplify for loose matching\n",
    "    return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
    "\n",
    "name_to_path = {}\n",
    "for p in candidates:\n",
    "    if arcpy.Exists(p):\n",
    "        b = base(p)\n",
    "        name_to_path[b] = p\n",
    "        name_to_path[norm(b)] = p\n",
    "\n",
    "feature_order = cont_cols + lith_cols  # same order the model expects\n",
    "feat_to_path, missing = {}, []\n",
    "for f in feature_order:\n",
    "    p = name_to_path.get(f) or name_to_path.get(norm(f)) or manual.get(f.lower())\n",
    "    # Try stripping numeric suffix (_1,_2) if present\n",
    "    if not p and \"_\" in f and f.split(\"_\")[-1].isdigit():\n",
    "        base_no = \"_\".join(f.split(\"_\")[:-1])\n",
    "        p = name_to_path.get(base_no) or name_to_path.get(norm(base_no)) or manual.get(base_no.lower())\n",
    "    if p and arcpy.Exists(p):\n",
    "        feat_to_path[f] = p\n",
    "    else:\n",
    "        missing.append(f)\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(\"‚ùå No raster found for these model features: \"\n",
    "                       + \", \".join(missing)\n",
    "                       + \"\\nAdd them to `manual` above or adjust paths.\")\n",
    "\n",
    "print(\"‚úÖ Feature ‚Üí raster paths resolved:\", len(feat_to_path), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = arcpy.Raster(REF_RASTER)\n",
    "arcpy.env.snapRaster = ref\n",
    "arcpy.env.extent     = ref.extent\n",
    "arcpy.env.cellSize   = ref.meanCellWidth\n",
    "\n",
    "cell_x = ref.meanCellWidth\n",
    "cell_y = ref.meanCellHeight\n",
    "ncols  = ref.width\n",
    "nrows  = ref.height\n",
    "ext    = ref.extent\n",
    "ll_all = arcpy.Point(ext.XMin, ext.YMin)\n",
    "\n",
    "out_prob = np.full((nrows, ncols), np.nan, dtype=\"float32\")\n",
    "nodata_out = -9999.0\n",
    "\n",
    "def read_block(rpath, ll_pt, ncols, nrows):\n",
    "    \"\"\"Read a raster block, cast to float, set NoData ‚Üí NaN.\"\"\"\n",
    "    ras = arcpy.Raster(rpath)\n",
    "    arr = arcpy.RasterToNumPyArray(ras, ll_pt, ncols, nrows).astype(\"float32\")\n",
    "    nd = ras.noDataValue\n",
    "    if nd is not None:\n",
    "        arr[arr == nd] = np.nan\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block r8192:8938 c8192:9031 done\n",
      "‚úÖ All blocks predicted.\n"
     ]
    }
   ],
   "source": [
    "BLOCK = 1024  # pixels per side (tweak for memory/perf)\n",
    "\n",
    "for r0 in range(0, nrows, BLOCK):\n",
    "    rh = min(BLOCK, nrows - r0)\n",
    "    for c0 in range(0, ncols, BLOCK):\n",
    "        cw = min(BLOCK, ncols - c0)\n",
    "        ll_win = arcpy.Point(ext.XMin + c0*cell_x, ext.YMin + r0*cell_y)\n",
    "\n",
    "        # read all feature bands for this window\n",
    "        bands = []\n",
    "        for f in feature_order:\n",
    "            arr = read_block(feat_to_path[f], ll_win, cw, rh)\n",
    "            bands.append(arr.reshape(-1))\n",
    "        X_block = pd.DataFrame(np.vstack(bands).T, columns=feature_order)\n",
    "\n",
    "        # predict probabilities (pipeline handles impute/scale)\n",
    "        proba = rf.predict_proba(X_block)[:, 1].reshape(rh, cw)\n",
    "        out_prob[r0:r0+rh, c0:c0+cw] = proba\n",
    "\n",
    "        print(f\"Block r{r0}:{r0+rh} c{c0}:{c0+cw} done\", end=\"\\r\")\n",
    "\n",
    "print(\"\\n‚úÖ All blocks predicted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\OUTPUTS\\Prospectivity_RF.tif\n",
      "Saved: C:\\Users\\USER\\Desktop\\PROJECTS\\ESRI\\DATA\\OUTPUTS\\Targets_RF_binary.tif\n"
     ]
    }
   ],
   "source": [
    "# ---- Save probability raster ------------------------------------------------\n",
    "to_save = np.where(np.isfinite(out_prob), out_prob, nodata_out)\n",
    "rast_p  = arcpy.NumPyArrayToRaster(to_save, ll_all, cell_x, cell_y, nodata_out)\n",
    "rast_p.save(OUT_PROB)\n",
    "print(\"Saved:\", OUT_PROB)\n",
    "\n",
    "# ---- Save binary targets raster (using THRESH_RF) ---------------------------\n",
    "bin_arr = np.zeros_like(to_save, dtype=\"uint8\")\n",
    "valid   = np.isfinite(out_prob)\n",
    "bin_arr[valid] = (out_prob[valid] >= THRESH_RF).astype(\"uint8\")\n",
    "nodata_bin = 255  # nodata marker for byte raster\n",
    "bin_arr[~valid] = nodata_bin\n",
    "rast_b = arcpy.NumPyArrayToRaster(bin_arr, ll_all, cell_x, cell_y, nodata_bin)\n",
    "rast_b.save(OUT_BIN)\n",
    "print(\"Saved:\", OUT_BIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
